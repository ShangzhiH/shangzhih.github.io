<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Shangzhi HUANG" />
        <meta name="copyright" content="Shangzhi HUANG" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="adaboost, 算法, spark, 朴素贝叶斯, 文本分类, 机器学习, 机器学习, " />

<meta property="og:title" content="Spark ML下实现的多分类adaboost+naivebayes算法在文本分类上的应用 "/>
<meta property="og:url" content="/spark-mlxia-shi-xian-de-duo-fen-lei-adaboostnaivebayessuan-fa-zai-wen-ben-fen-lei-shang-de-ying-yong.html" />
<meta property="og:description" content="1. Naive Bayes算法 朴素贝叶斯算法算是生成模型中一个最经典的分类算法之一了，常用的有Bernoulli和Multinomial两种。在文本分类上经常会用到这两种方法。在词袋模型中，对于一篇文档\(d\)中出现的词\(w_0,w_1,...,w_n\), 这篇文章被分类为\(c\)的概率为 $$p(c|w_0,w_1,...,w_n) = \frac{p(c,w_0,w_1,...,w_n)}{p(w_0,w_1,...,w_n)} = \frac{p(w_0,w_1,...,w_n|c)*p(c)}{p(w_0,w_1,...,w_n)}$$ 对于一篇给定文章，分母为常数，基于朴素贝叶斯的各词在一篇文章中出现独立性假设，最后我们需要比较的就是在不同类别\(c\)下\(p …" />
<meta property="og:site_name" content="Shangzhi HUANG&#39;s Blog" />
<meta property="og:article:author" content="Shangzhi HUANG" />
<meta property="og:article:published_time" content="2017-08-05T20:00:00+08:00" />
<meta name="twitter:title" content="Spark ML下实现的多分类adaboost+naivebayes算法在文本分类上的应用 ">
<meta name="twitter:description" content="1. Naive Bayes算法 朴素贝叶斯算法算是生成模型中一个最经典的分类算法之一了，常用的有Bernoulli和Multinomial两种。在文本分类上经常会用到这两种方法。在词袋模型中，对于一篇文档\(d\)中出现的词\(w_0,w_1,...,w_n\), 这篇文章被分类为\(c\)的概率为 $$p(c|w_0,w_1,...,w_n) = \frac{p(c,w_0,w_1,...,w_n)}{p(w_0,w_1,...,w_n)} = \frac{p(w_0,w_1,...,w_n|c)*p(c)}{p(w_0,w_1,...,w_n)}$$ 对于一篇给定文章，分母为常数，基于朴素贝叶斯的各词在一篇文章中出现独立性假设，最后我们需要比较的就是在不同类别\(c\)下\(p …">

        <title>Spark ML下实现的多分类adaboost+naivebayes算法在文本分类上的应用  · Shangzhi HUANG&#39;s Blog
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">
        <link rel="shortcut icon" href="/theme/images/favicon.ico" type="image/x-icon" type="image/png" />
        <link rel="icon" href="/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link href="/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Shangzhi HUANG&#39;s Blog - Full RSS Feed" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="/"><span class=site-name>Shangzhi HUANG's Blog</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="/">Home</a></li>
                            <li ><a href="/categories.html">Categories</a></li>
                            <li ><a href="/tags.html">Tags</a></li>
                            <li ><a href="/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="/spark-mlxia-shi-xian-de-duo-fen-lei-adaboostnaivebayessuan-fa-zai-wen-ben-fen-lei-shang-de-ying-yong.html"> Spark ML下实现的多分类adaboost+naivebayes算法在文本分类上的应用  </a></h1>
    </header>
</div>

<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div class="toc">
<ul>
<li><a href="#1-naive-bayes">1. Naive Bayes算法</a><ul>
<li><a href="#bernoulli">Bernoulli</a></li>
<li><a href="#multinomial">Multinomial</a></li>
</ul>
</li>
<li><a href="#2-adaboost">2. Adaboost算法</a><ul>
<li><a href="#21-adaboost">2.1 二分类adaboost</a></li>
<li><a href="#22-adaboost">2.2 多分类adaboost</a></li>
</ul>
</li>
<li><a href="#3-spark-ml">3. Spark ML的使用</a></li>
<li><a href="#4-spark-ml">4. 自定义扩展Spark ML</a><ul>
<li><a href="#41">4.1 模型参数</a></li>
<li><a href="#42-estimator">4.2 模型Estimator</a></li>
<li><a href="#43-transformer">4.3 模型Transformer</a></li>
</ul>
</li>
<li><a href="#5">5. 写在最后</a></li>
<li><a href="#_1">参考资料</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="span8 article-content">

            
            
<h2 id="1-naive-bayes">1. Naive Bayes算法</h2>
<p>朴素贝叶斯算法算是生成模型中一个最经典的分类算法之一了，常用的有Bernoulli和Multinomial两种。在文本分类上经常会用到这两种方法。在词袋模型中，对于一篇文档<span class="math">\(d\)</span>中出现的词<span class="math">\(w_0,w_1,...,w_n\)</span>, 这篇文章被分类为<span class="math">\(c\)</span>的概率为</p>
<div class="math">$$p(c|w_0,w_1,...,w_n) = \frac{p(c,w_0,w_1,...,w_n)}{p(w_0,w_1,...,w_n)} = \frac{p(w_0,w_1,...,w_n|c)*p(c)}{p(w_0,w_1,...,w_n)}$$</div>
<p> 对于一篇给定文章，分母为常数，基于朴素贝叶斯的各词在一篇文章中出现独立性假设，最后我们需要比较的就是在不同类别<span class="math">\(c\)</span>下<span class="math">\(p(w_0|c)*p(w_1|c)*...*p(w_n|c)*p(c)\)</span>的大小。</p>
<p>naive bayes模型的参数就是在每个类别<span class="math">\(c\)</span>下各词出现的概率的<span class="math">\(p(w_0|c),p(w_1|c),...,p(w_n|c))\)</span>和该类别出现的概率<span class="math">\(p(c)\)</span>，参数的估计通常就是根据训练样本进行词频的统计并计算相应概率，其中</p>
<div class="math">$$p(c) = \frac{count(c)}{count(doc)}$$</div>
<p>，即为训练数据中c类别文章的总数量除以训练集中文章的总数量。针对<span class="math">\(p(w_i|c)\)</span>的估计，Bernoulli和Multinomial略有不同。</p>
<h3 id="bernoulli">Bernoulli</h3>
<p>文章中某词<span class="math">\( w_i\)</span>出现过，则记为1，所以</p>
<div class="math">$$p(w_i|c) = \frac{count(w_i,c)}{count(c)}$$</div>
<p> 即为在类别为c的训练集文章中出现词<span class="math">\(w_i\)</span>的文章数量除以训练集中为别为c的文章总数量</p>
<h3 id="multinomial">Multinomial</h3>
<p>这种情况下文章的词并不是非0即1的one hot特征，而是带有权重的数值特征，通常可以使用tf或者tf-idf值。</p>
<div class="math">$$p(w_i|c) = \frac{T_{ci}}{\sum_{t}{T_{ct}}}$$</div>
<p> 其中<span class="math">\(T_{ci}\)</span>为类别c的训练文章中词<span class="math">\(w_i\)</span>的所有权重和，<span class="math">\(\sum_{t}{T_{ct}}\)</span>为类别c的文章中所有词的权重之和。预测的时候对于词<span class="math">\(w_i\)</span>计算该词在该文章中的权重<span class="math">\(T_i\)</span>，使用<span class="math">\(p(w_i|c)^{T_i}\)</span>作为连乘部分的概率。不过实际上经常使用对数概率，所以可以将指数运算变为乘法运算，在代码中就可以利用矩阵相乘直接计算。</p>
<p>还有一些细节问题，例如数据稀疏，平滑处理等因为不是本文的重点，这里就不详细解释了。</p>
<h2 id="2-adaboost">2. Adaboost算法</h2>
<p>作为一种boosting方法，adaboost在很多算法上都有着不俗的表现。不过在基于naive bayes的文档分类领域，貌似实际效果很一般。在stack overflow上也看到有人讨论，说adaboost对于多个弱分类器的提升效果很不错，但是naive bayes的文档分类通常已经有很不错的表现了，提升效果一般。不过不管效果提升怎么样，实现一下试试也没什么坏处，顺便还可以熟悉一下spark的相关操作。经典的adaboost算法适用于二分类的情况，但是我们的文本是多分类的情况，依靠多个二分类器表决不失为一种方法，但是比较麻烦，好在找到了介绍多分类adaboost算法的论文，照着论文依葫芦画瓢也不难。下面先分别多分类和二分类的adaboost</p>
<h3 id="21-adaboost">2.1 二分类adaboost</h3>
<p>对于给定的二类分类的训练数据集</p>
<div class="math">$$T = {(x_1, y_2),(x_2, y_2)...,(x_N, y_N)}$$</div>
<p> 其中每个<span class="math">\(x\)</span>是一个样本的特征向量，<span class="math">\(y\in\{-1, +1\}\)</span>，算法流程如下：</p>
<ol>
<li>
<p>初始化各个样本的权重为<div class="math">$$D_1 = (w_{11}, w_{12}, ... , w_{1i}, ... , w_{1N}),  w_{1i} = \frac{1}{N}, i = 1, 2, ... , N$$</div>
</p>
</li>
<li>
<p>对于第m次迭代，<span class="math">\(m = 1, 2, ..., M\)</span>：</p>
<ul>
<li>每次迭代使用带有当前权重<span class="math">\(D_m\)</span>的样本进行训练，得到一个基本分类器<span class="math">\(G_m(x)\)</span></li>
<li>计算在分类器<span class="math">\(D_m\)</span>下，训练样本分类结果的误差率<div class="math">$$e_m = \sum^{N}_{i = 1}{w_{mi}I(G_m{x_i} \neq{y_i})}$$</div>，因为每一步权重都做了归一化，所以分母不用再除以样本权重之和</li>
<li>根据误差率<span class="math">\(e_m\)</span>计算分类器<span class="math">\(D_m\)</span>的系数 <div class="math">$$\alpha_m = log\frac{1-e_m}{e_m}$$</div>
</li>
<li>根据系数<span class="math">\(\alpha_m\)</span>更新各样本的权重<div class="math">$$D_{m+1} = {w_{m+1, 1}, w_{m+1, 2}, ... , w_{m+1, N}}$$</div>
<div class="math">$$w_{m+1, i} = w_{m, i} * exp(\alpha_m * I(G_m{x_i} \neq{y_i}))$$</div>
</li>
<li>对<span class="math">\(D_{m+1}\)</span>做归一化处理，使<span class="math">\(\sum_{i = 1}^{N}{w_{m+1, i}} = 1\)</span></li>
</ul>
</li>
<li>
<p>最后对多个分类器<span class="math">\(D_m\)</span>的结果进行加权表决，<div class="math">$$c(x) = argmax_k\sum_{m = 1}^{M}{\alpha_m*I(D_m(x) = k)}$$</div>
</p>
</li>
</ol>
<p>注意到对于二分类的adaboost需要每次的分类误差率<span class="math">\(e_m \leq{\frac{1}{2}}\)</span>，否则的话将会导致<span class="math">\(\alpha_m &lt; 0\)</span>，然后样本权重的更新将会朝着反方向进行。</p>
<h3 id="22-adaboost">2.2 多分类adaboost</h3>
<p>对于K分类的情况，算法基本与二分类的情况一致。但是要求每次的分类误差率<span class="math">\(e_m \leq{\frac{1}{2}}\)</span>是非常困难的，联系到二分类误差率阈值选择<span class="math">\(\frac{1}{2}\)</span>，K分类的情况选择误差率为<span class="math">\(\frac{K-1}{K}\)</span>，然后<span class="math">\(\alpha_m\)</span>的计算改为 </p>
<div class="math">$$\alpha_m = log(\frac{1-e_m}{e_m}) + log(K-1)$$</div>
<p> 容易验证只要<span class="math">\(e_m \leq{\frac{K-1}{K}}\)</span>，则有<span class="math">\(\alpha_m \geq{log(\frac{1-\frac{K-1}{K}}{\frac{K-1}{K}}) + log(K-1)} = log(\frac{1}{K-1}) + log(K-1) = 0\)</span>，这种情况下，多分类adaboost对于被误分的样本的侧重加大了，因为<span class="math">\(\alpha_m\)</span>因为添加了正项<span class="math">\(log(K-1)\)</span>而增大了。</p>
<p>adaboost的一种解释是模型为加法模型，损失函数为指数函数，学习算法为前向分步算法的分类算法，这个以后再另外写一篇。这里给出一个比较直观好懂的解释：</p>
<ul>
<li>迭代过程中误差率小的模型具有大的模型系数，也就是说表现好的子模型在最后加权的时候具有更大的“话语权”</li>
<li>迭代过程中上一次被误分的样本在下一次训练时将会具有更大的权重，更容易被分类正确</li>
</ul>
<h2 id="3-spark-ml">3. Spark ML的使用</h2>
<p>提到Spark ml就不得不提Spark mllib，两者的区别主要在于ml面向的数据是Dataset，而mllib面向的是rdd，Dataset相当于在底层rdd的基础上做了进一步的优化。而且ml中一系列算法更适合创建包含从数据清洗到特征工程再到模型训练等一系列工作的ML pipelines，这个类似于sklearn中的pipeline，非常简洁好用。</p>
<p>pipeline中的Transformer，Estimator，Stage等概念<a href="https://spark.apache.org/docs/latest/ml-pipeline.html">官方文档</a>上写的很清楚，而且还有事例，就不在这里解释了。这里以naive bayes为例简单介绍一下怎么利用spark ml的pipelines进行机器学习模型的训练和预测。</p>
<p>首先是pipelines的创建：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1">// pipeline for train </span>
<span class="k">def</span> <span class="n">createPipiline</span><span class="o">(</span><span class="n">dataset</span><span class="k">:</span> <span class="kt">Dataset</span><span class="o">[</span><span class="k">_</span><span class="o">])</span><span class="k">:</span> 
    <span class="kt">Pipeline</span> <span class="o">={</span> 
    <span class="c1">//step 1 sentence 拆成 words </span>
    <span class="k">val</span> <span class="n">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexTokenizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">"words"</span><span class="o">).</span><span class="n">setPattern</span><span class="o">(</span><span class="s">","</span><span class="o">)</span> 
    <span class="c1">//step 2 label 转化为以0开始的labelIndex 为了适应spark.ml </span>
    <span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StringIndexer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">"labelIndex"</span><span class="o">).</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span> 
    <span class="c1">//step3 统计tf词频 </span>
    <span class="k">val</span> <span class="n">countModel</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CountVectorizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">"words"</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">"rawFeatures"</span><span class="o">)</span> 
    <span class="c1">//step4 tf-idf 10 </span>
    <span class="k">val</span> <span class="n">idfModel</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IDF</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">"rawFeatures"</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span> 
    <span class="c1">//step5 normalize tf-idf vector </span>
    <span class="k">val</span> <span class="n">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">"normalizedFeatures"</span><span class="o">)</span> 
    <span class="c1">//step6 naive bayes model </span>
    <span class="k">val</span> <span class="n">naiveBayes</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NaiveBayes</span><span class="o">().</span><span class="n">setFeaturesCol</span><span class="o">(</span><span class="s">"normalizedFeatures"</span><span class="o">).</span><span class="n">setLabelCol</span><span class="o">(</span><span class="s">"labelIndex"</span><span class="o">).</span><span class="n">setWeightCol</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">).</span><span class="n">setPredictionCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">).</span><span class="n">setModelType</span><span class="o">(</span><span class="s">"multinomial"</span><span class="o">).</span><span class="n">setSmoothing</span><span class="o">(</span><span class="mf">1.0</span><span class="o">)</span> 
    <span class="c1">//step7 predict label to real label </span>
    <span class="k">val</span> <span class="n">labelConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IndexToString</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">"predictedLabel"</span><span class="o">).</span><span class="n">setLabels</span><span class="o">(</span><span class="n">indexer</span><span class="o">.</span><span class="n">labels</span><span class="o">)</span> 
    <span class="n">newPipeline</span><span class="o">().</span><span class="n">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">tokenizer</span><span class="o">,</span> <span class="n">indexer</span><span class="o">,</span> <span class="n">countModel</span><span class="o">,</span> <span class="n">idfModel</span><span class="o">,</span> <span class="n">normalizer</span><span class="o">,</span> <span class="n">naiveBayes</span><span class="o">,</span> <span class="n">labelConverter</span><span class="o">))</span> <span class="o">}</span>
</pre></div>
</td></tr></table>
<p>这里注意到我在创建这个pipeline的时候还传入了训练数据，但是一般情况下训练数据是在拟合模型而不是在模型建立的时候就提前传入的。这里是因为最后面那个labelConverter的transformer需要使用indexer.labels这个参数，而indexer要获取这个参数就要提前拟合训练数据，也就是indexer的创建发生在整个pipeline的拟合之前，所以我就先穿入了训练数据集。注意到这里训练数据就相当于被训练了两次，所以可以先cache()操作一下。</p>
<p>pipeline创建好以后的使用就相对简单多了，传入数据就可以了。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">pipeline</span> <span class="k">=</span> <span class="nc">ModelUsage</span><span class="o">.</span><span class="n">createPipeline</span><span class="o">(</span><span class="n">dataRDDTrain</span><span class="o">)</span> 
<span class="c1">// train and test </span>
<span class="k">val</span> <span class="n">combinedModel</span> <span class="k">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataRDDTrain</span><span class="o">)</span> 
<span class="k">val</span> <span class="n">predictResult</span> <span class="k">=</span> <span class="n">combinedModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataRDDTest</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">"predictedLabel"</span><span class="o">,</span> <span class="s">"label"</span><span class="o">).</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">row</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">row</span><span class="o">.</span><span class="n">getDouble</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">row</span><span class="o">.</span><span class="n">getDouble</span><span class="o">(</span><span class="mi">1</span><span class="o">)))</span> 
<span class="k">val</span> <span class="n">evaluator</span> <span class="k">=</span> <span class="n">newMulticlassMetrics</span><span class="o">(</span><span class="n">predictResult</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">"confusionMatrix:"</span><span class="o">)</span> 
<span class="n">println</span><span class="o">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">confusionMatrix</span><span class="o">)</span> 
<span class="n">println</span><span class="o">(</span><span class="n">evaluator</span><span class="o">.</span><span class="n">accuracy</span><span class="o">)</span>
</pre></div>
</td></tr></table>
<p>注意到ML拟合的结果都是Double类型的，比如说我一个label是55但是输出是55.0，评估模型准确度的时候注意一下就好，影响不大。</p>
<p>Spark ML的一个好处是数据dataset像水一样通过预先创建好的pipeline，可以指定每一个stage处理的column名，再添加生成的数据到新的一列。自始至终，这些中间数据都在结果的dataset里，想要哪些数据指定列名就可以了。这样的话就避免了每次都要处理数据使它们符合中间模型的输入结构，而且最后还要自己再整合需要的字段到一起。</p>
<p>由于我们的文章数据特点比较鲜明，没有任何参数调优，在4w(80% train 20% test)的四分类数据上就已经有了95%的正确率了。</p>
<h2 id="4-spark-ml">4. 自定义扩展Spark ML</h2>
<p>既然直接用现有naive bayes模型就已经有了95%的正确率，那要是加上adaboost呢？</p>
<p>直接实现adaboost算法很简单，但是毕竟spark ml的pipeline这么好用，而dataset这么好的封装加上这么多现有的类似StringIndxer等工具类transformer总不能全部重写吧。所以就想到怎么去自定义一个跟Spark ML兼容的model，上网查了查相关资料，在已有的naivebayes模型基础上进行了改进实现了与Spark ML兼容的adaboost naivebayes model。</p>
<p><strong>注意</strong></p>
<ol>
<li>
<p>由于我们的模型需要先拟合训练数据得到模型，随后才能使用模型，这里面分别涉及到estimator和transformer，因此我们需要分别实现这两个部分。</p>
</li>
<li>
<p>我要实现的adaboost+naivebayes模型是一个概率模型，因此我的Estimator和Transformer分别继承自ProbabilisticClassifier和ProbabilisticClassificationModel，而不是最原始的Estimator和Transformer，这样就减少了很多不必要的代码重写，但是如果是想玩玩整整自己实现一个模型的话就要从最基本的一点点开始写了，可以参照上面第一篇文章所讲，这里就不多细说了。</p>
</li>
</ol>
<p>当然可能会有疑问，既然可以继承ProbabilisticClassifier，那为什么不直接集成NaiveBayes不是更简单么？我一开始也是这样想的，但是发现Spark ML里NaiveBayes里大部分方法和属性都是私有或者受保护的，我要改就得修改Spark源码，但是我的Spark程序是在公司服务器运行的，总不能每次都让公司用我改过之后的Spark包吧。。。</p>
<h3 id="41">4.1 模型参数</h3>
<p>首先，对于任何一个模型模型的训练，我们一般都会需要传递一些参数，这里利用scala的trait实现一个参数接口。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">trait</span> <span class="nc">AdaboostNaiveBayesParams</span> <span class="n">extendsParams</span> <span class="o">{</span> 
    <span class="c1">//进行adaboost时的最高迭代次数 </span>
    <span class="k">final</span> <span class="k">val</span> <span class="n">maxIter</span><span class="k">:</span> <span class="kt">IntParam</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">IntParam</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="s">"maxIter"</span><span class="o">,</span> <span class="s">"max number of iterations"</span><span class="o">)</span> 
    <span class="k">def</span> <span class="n">getMaxIter</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span><span class="n">$</span><span class="o">(</span><span class="n">maxIter</span><span class="o">)</span> 
        <span class="c1">//进行adaboost时准确率变化小于某个阈值时迭代提前终止 </span>
        <span class="k">final</span> <span class="k">val</span> <span class="n">threshold</span><span class="k">:</span> <span class="kt">DoubleParam</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">DoubleParam</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="s">"threshold"</span><span class="o">,</span> <span class="s">"improvement threshold among iterations"</span><span class="o">)</span> 
    <span class="k">def</span> <span class="n">getThreshold</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span><span class="n">$</span><span class="o">(</span><span class="n">threshold</span><span class="o">)</span> 
        <span class="c1">//朴素Bayes的平滑系数 </span>
        <span class="k">final</span> <span class="k">val</span> <span class="n">smoothing</span> <span class="k">:</span> <span class="kt">DoubleParam</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">DoubleParam</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="s">"smoothing"</span><span class="o">,</span> <span class="s">"naive bayes smooth"</span><span class="o">)</span> 
    <span class="k">def</span> <span class="n">getSmoothing</span> <span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span><span class="n">$</span><span class="o">(</span><span class="n">smoothing</span><span class="o">)</span> 
        <span class="c1">//朴素Bayes类型"multinomial"(default) and "bernoulli" </span>
        <span class="k">final</span> <span class="k">val</span> <span class="n">modelType</span> <span class="k">:</span> <span class="kt">Param</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Param</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="k">this</span><span class="o">,</span> <span class="s">"modelType"</span><span class="o">,</span> <span class="s">"naive bayes model type"</span><span class="o">)</span> 
    <span class="k">def</span> <span class="n">getModelType</span> <span class="k">:</span> <span class="kt">String</span> <span class="o">=</span><span class="n">$</span><span class="o">(</span><span class="n">modelType</span><span class="o">)</span> <span class="mi">14</span> <span class="o">}</span>
</pre></div>
</td></tr></table>
<p>这一部分没什么解释的，都是一些模型常用参数。</p>
<h3 id="42-estimator">4.2 模型Estimator</h3>
<p>这一部分可以说是最重要的部分，Estimator拟合好了，Transformer基本属于调用一下就好了。先贴代码，再一行行解释。</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">classAdaboostNaiveBayes</span><span class="o">(</span><span class="k">override</span> <span class="k">val</span> <span class="n">uid</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">ProbabilisticClassifier</span><span class="o">[</span><span class="kt">Vector</span>, <span class="kt">AdaboostNaiveBayes</span>, <span class="kt">AdaboostNaiveBayesModel</span><span class="o">]</span> <span class="k">with</span> <span class="nc">AdaboostNaiveBayesParams</span> <span class="o">{</span> 
    <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="k">=</span> <span class="k">this</span><span class="o">(</span><span class="nc">Identifiable</span><span class="o">.</span><span class="n">randomUID</span><span class="o">(</span><span class="s">"AdaboostNaiveBayes"</span><span class="o">))</span> 
    <span class="c1">//model parameters assignment </span>
    <span class="k">def</span> <span class="n">setMaxIter</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">this.</span><span class="k">type</span> <span class="o">=</span><span class="n">set</span><span class="o">(</span><span class="n">maxIter</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> 
    <span class="k">def</span> <span class="n">setThreshold</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">this.</span><span class="k">type</span> <span class="o">=</span><span class="n">set</span><span class="o">(</span><span class="n">threshold</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span>  
    <span class="k">def</span> <span class="n">setSmoothing</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="kt">this.</span><span class="k">type</span> <span class="o">=</span><span class="n">set</span><span class="o">(</span><span class="n">smoothing</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> 
    <span class="k">def</span> <span class="n">setModelType</span><span class="o">(</span><span class="n">value</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">this.</span><span class="k">type</span> <span class="o">=</span><span class="n">set</span><span class="o">(</span><span class="n">modelType</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span>

    <span class="n">setMaxIter</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span> 
    <span class="n">setThreshold</span><span class="o">(</span><span class="mf">0.02</span><span class="o">)</span> 
    <span class="n">setSmoothing</span><span class="o">(</span><span class="mf">1.0</span><span class="o">)</span> 
    <span class="n">setModelType</span><span class="o">(</span><span class="s">"multinomial"</span><span class="o">)</span>

    <span class="c1">//method used by fit()</span>
    <span class="k">override</span> <span class="k">protected</span> <span class="k">def</span> <span class="n">train</span><span class="o">(</span><span class="n">dataset</span><span class="k">:</span> <span class="kt">Dataset</span><span class="o">[</span><span class="k">_</span><span class="o">])</span><span class="k">:</span> <span class="kt">AdaboostNaiveBayesModel</span> <span class="o">={</span> 
        <span class="k">val</span> <span class="n">datasetSize</span> <span class="k">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">count</span><span class="o">().</span><span class="n">toInt</span> 
        <span class="k">val</span> <span class="n">labelSize</span> <span class="k">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">"label"</span><span class="o">).</span><span class="n">distinct</span><span class="o">().</span><span class="n">count</span><span class="o">()</span>

        <span class="c1">//各子模型及其权重 </span>
        <span class="k">val</span> <span class="n">modelWeights</span> <span class="k">=</span> <span class="n">newArray</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">$</span><span class="o">(</span><span class="n">maxIter</span><span class="o">))</span>  
        <span class="k">val</span> <span class="n">modelArray</span> <span class="k">=</span> <span class="n">newArray</span><span class="o">[</span><span class="kt">NaiveBayesModel</span><span class="o">](</span><span class="n">$</span><span class="o">(</span><span class="n">maxIter</span><span class="o">))</span> 
        <span class="k">var</span> <span class="n">alpha</span> <span class="k">=</span> <span class="mf">0.0</span> 
        <span class="c1">//初始化各样本等权重 </span>
        <span class="k">val</span> <span class="n">dataWeight</span><span class="k">:</span> <span class="o">(</span><span class="kt">Double</span><span class="o">,</span> <span class="kt">Double</span><span class="o">,</span> <span class="nc">Double</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">Double</span> <span class="k">=</span> <span class="o">(</span><span class="n">obsWeight</span><span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">labelIndex</span><span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">prediction</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="o">=&gt;{</span> 
            <span class="k">if</span> <span class="o">(</span><span class="n">labelIndex</span> <span class="o">==</span><span class="n">prediction</span><span class="o">)</span> <span class="o">{</span> 
                <span class="n">obsWeight</span> 
            <span class="o">}</span>
            <span class="k">else</span><span class="o">{</span> 
                <span class="n">obsWeight</span> <span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="o">(</span><span class="n">alpha</span><span class="o">)</span> 
            <span class="o">}</span>
        <span class="o">}</span> 
        <span class="k">val</span> <span class="n">sqlfunc</span> <span class="k">=</span><span class="n">udf</span><span class="o">(</span><span class="n">dataWeight</span><span class="o">)</span> 
        <span class="c1">//初始化还没有prediction </span>
        <span class="k">var</span> <span class="n">temp</span> <span class="k">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">,</span> <span class="n">lit</span><span class="o">(</span><span class="mf">1.0</span><span class="o">))</span> 
        <span class="k">var</span> <span class="n">i</span> <span class="k">=</span> <span class="mi">0</span> <span class="mi">42</span> <span class="k">var</span> <span class="n">error1</span> <span class="k">=</span> <span class="mf">2.0</span> 
        <span class="k">var</span> <span class="n">error2</span> <span class="k">=</span> <span class="mf">1.0</span><span class="c1">//&amp;&amp; (error1 - error2) &gt; $(threshold) </span>
        <span class="k">var</span> <span class="n">weightSum</span> <span class="k">=</span> <span class="n">datasetSize</span><span class="o">.</span><span class="n">toDouble</span><span class="o">*</span><span class="n">datasetSize</span>

        <span class="k">while</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span><span class="n">$</span><span class="o">(</span><span class="n">maxIter</span><span class="o">))</span> <span class="o">{</span> 
            <span class="k">val</span> <span class="n">naiveBayes</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NaiveBayes</span><span class="o">().</span><span class="n">setFeaturesCol</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">featuresCol</span><span class="o">)).</span><span class="n">setLabelCol</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">labelCol</span><span class="o">)).</span><span class="n">setWeightCol</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">).</span><span class="n">setPredictionCol</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">predictionCol</span><span class="o">)).</span><span class="n">setModelType</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">modelType</span><span class="o">)).</span><span class="n">setSmoothing</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">smoothing</span><span class="o">)).</span><span class="n">fit</span><span class="o">(</span><span class="n">temp</span><span class="o">)</span> 
            <span class="n">temp</span> <span class="k">=</span><span class="n">naiveBayes</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">temp</span><span class="o">).</span><span class="n">cache</span><span class="o">()</span> 
            <span class="k">var</span> <span class="n">error</span> <span class="k">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">"labelIndex"</span><span class="o">,</span> <span class="s">"prediction"</span><span class="o">,</span> <span class="s">"obsWeights"</span><span class="o">).</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">row</span> <span class="o">=&gt;{</span> 
                <span class="k">if</span> <span class="o">(</span><span class="n">row</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">!=</span> <span class="n">row</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span> 
                    <span class="n">row</span><span class="o">.</span><span class="n">getDouble</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> 
                <span class="k">else</span> 
                    <span class="mf">0.0</span>
            <span class="o">}).</span><span class="n">sum</span><span class="o">()/(</span><span class="n">datasetSize</span><span class="o">)</span> 
        <span class="n">error1</span> <span class="k">=</span><span class="n">error2</span> 
        <span class="n">error2</span> <span class="k">=</span><span class="n">error</span> 
        <span class="n">alpha</span> <span class="k">=</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">((</span><span class="n">labelSize</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span> <span class="o">*</span> <span class="o">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error</span><span class="o">)</span> <span class="o">/</span><span class="n">error</span><span class="o">)</span> 
        <span class="n">modelWeights</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="k">=</span><span class="n">alpha</span> 
        <span class="n">modelArray</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="k">=</span><span class="n">naiveBayes</span> 
        <span class="c1">//更新权重 </span>
        <span class="n">temp</span> <span class="k">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">,</span> <span class="n">sqlfunc</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">),</span> <span class="n">col</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">labelCol</span><span class="o">)),</span> <span class="n">col</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">predictionCol</span><span class="o">))));</span> 
        <span class="n">weightSum</span> <span class="k">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">).</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">row</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">row</span><span class="o">.</span><span class="n">getDouble</span><span class="o">(</span><span class="mi">0</span><span class="o">))).</span><span class="n">sum</span><span class="o">()</span> 
        <span class="n">temp</span> <span class="k">=</span><span class="n">temp</span><span class="o">.</span><span class="n">drop</span><span class="o">(</span><span class="n">$</span><span class="o">(</span><span class="n">predictionCol</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="n">rawPredictionCol</span><span class="o">),</span> <span class="n">$</span><span class="o">(</span><span class="n">probabilityCol</span><span class="o">))</span> 
        <span class="n">temp</span> <span class="k">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">,</span> <span class="n">col</span><span class="o">(</span><span class="s">"obsWeights"</span><span class="o">)/(</span><span class="n">weightSum</span><span class="o">/</span><span class="n">datasetSize</span><span class="o">))</span>

        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">}</span> 
        <span class="n">newAdaboostNaiveBayesModel</span><span class="o">(</span><span class="n">uid</span><span class="o">,</span> <span class="n">i</span><span class="o">,</span> <span class="n">modelWeights</span><span class="o">,</span> <span class="n">modelArray</span><span class="o">)</span>  <span class="o">}</span> 
        <span class="k">override</span> <span class="k">def</span> <span class="n">copy</span><span class="o">(</span><span class="n">extra</span><span class="k">:</span> <span class="kt">ParamMap</span><span class="o">)</span><span class="k">:</span> <span class="kt">AdaboostNaiveBayes</span> <span class="o">=</span><span class="n">defaultCopy</span><span class="o">(</span><span class="n">extra</span><span class="o">)</span> <span class="o">}</span>
</pre></div>
</td></tr></table>
<p>1-3行是继承ProbabilisticClassifer和实现前面我们自己定义的AdaboostNaiveBayesParam参数接口，ProbabilisticClassifer的继承使用看看源码里NaiveBayes是怎么做的就可以照着学了。</p>
<p>5行是一个最基本的构造函数，分配给对象一个id值</p>
<p>77行是一个拷贝构造函数，这个必须要实现，最简单的可以直接像这里一样调用defaultCopy函数就好了。这个函数用来在引入新的参数的时候复制当前stage返回加入新参数后的一个新模型</p>
<p>8-11行是给模型设定初始参数用的，这几个函数没有定义在AdaboostNaiveBayesParam里是因为这些参数的传入只发生在模型拟合前，在预测的时候是不能设定的，所以对后面的Transformer应该是不可见的，因此只在这里定义。注意到这些函数的返回类型和模型类型一致，其实就是每一步都返回一个加入的参数的新的模型，这里就利用了之前的拷贝构造函数。</p>
<p>13-16行是给模型设定默认参数。</p>
<p>19行开始的train函数就是我们在对模型调用fit方法时使用的函数。返回的是一个AdaboostNaiveBayesModel，是我们随后需要定义的跟AdaboostNaiveBayes这个Estimator对应的Transformer。</p>
<p>21-22行分别获取数据集的数量和其中label的数量</p>
<p>25-26是初始化所有子模型及其权重，因为adaboost每一次迭代都会生成一个新的模型并计算该模型在最终结果投票时的权重。</p>
<p>30-38是一个自定义udf函数，对每个样本计算预测的label和真实label，并根据该样本的现有权重obsWeight进行更新，可以理解为如果分类正确，其权重不变，否则增大其权重。</p>
<p>40行 初始化所有样本为等权重，如果样本数据非常不平衡的话，可以尝试在这一步就引入偏差权重，我由于使用的数据各个类之间数量是一样的，所以全部初始话为1</p>
<p>41-44行初始化一些错误率等参数</p>
<p>46行开始进行adaboost迭代过程。</p>
<p>47-49行是在当前样本权重情况下调用普通的NaiveBayes进行训练的到当前迭代下的子模型</p>
<p>49行这个cache一定不能少，否则迭代的速度只能呵呵了，毕竟temp用到了非常多次的action。</p>
<p>51-57行是计算该模型的错误率</p>
<p>59-61行是更新误差，并计算该模型的权重alpha</p>
<p>63-64行是保存当前子模型和权重</p>
<p>66-69行是利用之前定义的udf函数更新所有样本的权重并对其进行归一化</p>
<p>74 行是利用计算得到的参数去构建一个AdaboostNaiveBayesModel，这里传入所有的子模型及其权重，i表示的是总迭代次数，就是子模型的数量。</p>
<h3 id="43-transformer">4.3 模型Transformer</h3>
<p>这里要实现的AdaboostNaiveBayesModel是从ProbabilisticClassificationModel，因此要手动实现对应的必须要的几个方法。</p>
<p>代码如下：</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">classAdaboostNaiveBayesModel</span><span class="o">(</span><span class="k">override</span> <span class="k">val</span> <span class="n">uid</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">val</span> <span class="n">iternums</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="k">val</span> <span class="n">modelWeights</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span> <span class="k">val</span> <span class="n">modelArray</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">NaiveBayesModel</span><span class="o">])</span> <span class="n">extendsProbabilisticClassificationModel</span><span class="o">[</span><span class="kt">Vector</span>, <span class="kt">AdaboostNaiveBayesModel</span><span class="o">]</span> <span class="k">with</span> <span class="nc">AdaboostNaiveBayesParams</span> <span class="o">{</span> 
    <span class="k">override</span> <span class="k">val</span> <span class="n">numClasses</span> <span class="k">=</span> <span class="n">modelArray</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">pi</span><span class="o">.</span><span class="n">size</span> 
    <span class="k">private</span> <span class="k">def</span> <span class="n">multinomialCalculation</span><span class="o">(</span><span class="n">features</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">=</span> <span class="o">{</span> 
        <span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">DenseVector</span><span class="o">(</span><span class="n">newArray</span><span class="o">(</span><span class="n">numClasses</span><span class="o">))</span> 
        <span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">0</span><span class="n">until</span> <span class="n">iternums</span><span class="o">)</span> <span class="o">{</span> 
            <span class="k">val</span> <span class="n">prob</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">=</span><span class="n">modelArray</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="n">theta</span><span class="o">.</span><span class="n">multiply</span><span class="o">(</span><span class="n">features</span><span class="o">)</span> 
            <span class="n">prob</span><span class="o">.</span><span class="n">foreachActive</span> <span class="o">{</span> <span class="o">(</span><span class="n">index</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="o">=&gt;{</span> 
                <span class="n">prob</span><span class="o">.</span><span class="n">toArray</span><span class="o">(</span><span class="n">index</span><span class="o">)</span> <span class="k">=</span> <span class="n">value</span> <span class="o">+</span><span class="n">modelArray</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="n">pi</span><span class="o">(</span><span class="n">index</span><span class="o">)</span> 
            <span class="o">}</span>   
        <span class="o">}</span> 
        <span class="n">result</span><span class="o">.</span><span class="n">toArray</span><span class="o">(</span><span class="n">prob</span><span class="o">.</span><span class="n">argmax</span><span class="o">)</span> <span class="k">=</span> <span class="n">result</span><span class="o">(</span><span class="n">prob</span><span class="o">.</span><span class="n">argmax</span><span class="o">)</span> <span class="o">+</span><span class="n">modelWeights</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> 
    <span class="o">}</span> 
    <span class="n">result</span>
<span class="o">}</span> 
<span class="k">override</span> <span class="k">def</span> <span class="n">predictRaw</span><span class="o">(</span><span class="n">features</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">={</span> 
    <span class="n">multinomialCalculation</span><span class="o">(</span><span class="n">features</span><span class="o">)</span> 
<span class="o">}</span> 
<span class="k">override</span> <span class="k">def</span> <span class="n">raw2probabilityInPlace</span><span class="o">(</span><span class="n">rawPrediction</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">=</span> <span class="o">{</span> 
    <span class="n">rawPrediction</span> <span class="k">match</span> <span class="o">{</span> 
        <span class="k">case</span> <span class="n">dv</span><span class="k">:</span> <span class="kt">DenseVector</span> <span class="o">=&gt;</span> 
            <span class="k">var</span> <span class="n">i</span> <span class="k">=</span> <span class="mi">0</span> <span class="mi">28</span> <span class="k">val</span> <span class="n">size</span> <span class="k">=</span> <span class="n">dv</span><span class="o">.</span><span class="n">size</span> 
            <span class="k">val</span> <span class="n">maxLog</span> <span class="k">=</span> <span class="n">dv</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span> 
            <span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">until</span> <span class="n">size</span><span class="o">)</span> <span class="o">{</span> 
                <span class="n">dv</span><span class="o">.</span><span class="n">values</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="k">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="o">(</span><span class="n">dv</span><span class="o">.</span><span class="n">values</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="o">-</span> <span class="n">maxLog</span><span class="o">)</span>
            <span class="o">}</span> 
            <span class="k">val</span> <span class="n">probSum</span> <span class="k">=</span> <span class="n">dv</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">sum</span> 
            <span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">0</span><span class="n">until</span> <span class="n">size</span><span class="o">)</span> <span class="o">{</span> 
                <span class="n">dv</span><span class="o">.</span><span class="n">values</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="k">=</span> <span class="n">dv</span><span class="o">.</span><span class="n">values</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="o">/</span><span class="n">probSum</span>
            <span class="o">}</span> 
            <span class="n">dv</span> 
        <span class="k">case</span> <span class="n">sv</span><span class="k">:</span> <span class="kt">SparseVector</span> <span class="o">=&gt;</span> <span class="k">throw</span> <span class="k">new</span> <span class="nc">RuntimeException</span><span class="o">(</span><span class="s">"Unexpected error in AdaboostNaiveBayesModel:  raw2probabilityInPlace encountered SparseVector"</span><span class="o">)}}</span>
    <span class="k">override</span> <span class="k">def</span> <span class="n">copy</span><span class="o">(</span><span class="n">extra</span><span class="k">:</span> <span class="kt">ParamMap</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
        <span class="n">defaultCopy</span><span class="o">(</span><span class="n">extra</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</td></tr></table>
<p>第5行是读取一下总的标签个数以供后面使用</p>
<p>44-46行是拷贝构造函数</p>
<p>20-22行是对一个输入计算它在各个label下的得分，这个得分的大小表示的是判断到该标签概率的大小，但是并不是概率值，因为我们的BayesModel模型参数是做了log变换的</p>
<p>24-43行是怎么讲结果向量转化为和为1的概率值，30-32行是个小技巧，我一开始好奇为什么一定要减掉maxLog，因为这个按理说并不会影响到后面的计算结果，后来发现这样能避免浮点数的问题，因为不减的话，会出现求完math.exp后值约为零的情况，导致后面的计算出现问题</p>
<p>这样就完成了概率模型需要的几个方法了，可以对一个输入给出一个概率向量，每个维度代表在这个类的概率。</p>
<h2 id="5">5. 写在最后</h2>
<p>利用自定义的adaboost+naivebayes模型，测试准确率从95%增加到了96.5%左右。由于训练数据比较好，95%已经很不错了，这里主要是通过写一个自定义模型学习一下Spark ML方面的知识。之前都只是听说过，从来没用过，学习一下还是很有必要的，毕竟不能总指望着单机就能搞定所有问题。</p>
<p>不过注意到这里我并不是从0开始造轮子，我是从ProbabilisticClassification继承过来加以修改的，如果想要做其他模型的修改还是推荐看上面的两篇文章，然后多看看Spark ML源码里类似的模型并根据自己的需要进行修改。</p>
<p>然后scala也是为了用Spark ML现学的，代码可以优化的地方估计很多。</p>
<p>这是本人第一篇博客，希望以后可以坚持写，作为对自己工作学习的总结笔记。</p>
<h2 id="_1">参考资料</h2>
<p>[1] <a href="https://www.researchgate.net/profile/Trevor_Hastie/publication/228947999_Multi-class_AdaBoost/links/0c960521b946de42a9000000.pdf">Multi-class AdaBoost</a> - T Hastie, S Rosset, J Zhu, H Zou</p>
<p>[2] <a href="https://www.oreilly.com/learning/extend-spark-ml-for-your-own-modeltransformer-types">Extend Spark ML for your own model/transformer types</a></p>
<p>[3] <a href="https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/classification/NaiveBayes.scala">spark的NaiveBayes实现源码</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            
            
            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="next-article"><a href="/shen-du-xue-xi-yu-shen-jing-wang-luo-bi-ji-1.html" title="Next: 《深度学习与神经网络》笔记1 - 使用神经网络识别手写数字">《深度学习与神经网络》笔记1 <small>使用神经网络识别手写数字</small></a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2017-08-05T20:00:00+08:00">2017  - 08  - 05</time>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#ji-qi-xue-xi-ref">机器学习
                <span>(3)</span>
</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="/tags.html#adaboost-ref">adaboost
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#ji-qi-xue-xi-ref">机器学习
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#po-su-bei-xie-si-ref">朴素贝叶斯
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#spark-ref">spark
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#suan-fa-ref">算法
                    <span>9</span>
</a></li>
                <li><a href="/tags.html#wen-ben-fen-lei-ref">文本分类
                    <span>1</span>
</a></li>
            </ul>
                <div class="widget blogroll">
                        <h4>Blogroll</h4>
                        <ul>
                            <li><a href="http://blogwall.us/">Blogwall</a></li>
                            <li><a href="http://www.matrix67.com/">Matrix67</a></li>
                            <li><a href="http://blog.echen.me/">EdwinChen</a></li>
                        </ul>
                </div><!-- /.blogroll -->
<h4>Contact</h4>
    <a href="mailto:shangzhi.huang@gmail.com" title="My email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
    <a href="https://github.com/ShangzhiH" title="My github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="feeds/all.rss.xml" title="Subscribe in a reader" class="sidebar-social-links" target="_blank">
    <i class="fa fa-rss sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>