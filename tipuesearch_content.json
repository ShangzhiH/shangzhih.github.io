{"pages":[{"title":"条件随机场CRF","text":"1. 概率无向图 不同于HMM中状态序列是有方向的，在CRF中，我们使用的是概率无向图模型。 状态与状态之间并没有谁推导出谁的先后关系( \\(P(y_n|y_{n-1}, y_{n-2}...y_1)\\) )，这里我们用的是序列整体的分布 \\(P(y_1,y_2,...y_n)\\) 。 因子分解 团： 对于无向图中的一个子集，如果该子集中任意两个点都是有边相连接的，那么这样的子集就叫做该无向图上的一个团 最大团： 对于一个团，如果无法添加另外一个点使得团增大，那么现有的团就是最大团 一个概率无向图总的的联合概率分布 \\(P(Y)\\) 可以分解为在其所有最大团上定义的一个势函数的积： $$P(Y) = \\frac{\\prod_C{\\Phi_C(Y_C)}}{Z}$$ 其中C是最大团的集合，对于其中每一个最大团，有一个势能函数 \\(\\Phi_C\\) ， \\(Y_C\\) 为属于这个最大团的节点， \\(Z=\\sum_Y{\\prod_C{\\Phi_C(Y_C)}}\\) 是一个规范化因子，目的是为了让 \\(P(Y)\\) 构成一个概率分布。 由于势函数是严格正的，所以一般就定义为指数函数 \\(exp(-E(Y_C))\\) 总结： 概率无向图模型的联合概率分布可以分解为其所有 最大团 上的势函数的积。 2. 条件随机场 定义 CRF里的条件指的是在给定随机变量X的条件下，随机变量Y的马尔科夫随机场。 通常情况，只使用线性链条件随机场，将其用于标注问题，条件概率为P(Y|X)。其中X是给定的观测序列，Y是需要标注的标注序列(状态序列)。 一般形式 $$P(Y_v|X, Y_w w\\neq v) = P(Y_v | X, Y_w w~v)$$ 对于任意节点v成立，则称条件概率分布P(Y|X)为条件随机场。 同HMM的条件概率相比较，可以更好的理解CRF的条件概率定义。首先，在HMM中，观测序列中每个位置的观测值只和它所处的状态有关，而在CRF中，所有的观测序列是作为一个整体X来处理的。其次，对于 \\(w\\neq v\\) 是说除了v以外的所有点， \\(w~v\\) 是说和v相邻的点，也就是状态序列某一位置的状态y只和与它有连接的状态值有关。 线性链形式 线性链形式顾名思义就是状态序列 \\(Y=(Y_1, Y_2, ..., Y_n)\\) 是线性的，也就是说某一位置的状态只和它前后两个状态相连。 $$P(Y_i |X, Y_1,...,Y_{i-1},Y_{i+1},...,Y_n) = P(Y_i|X, Y_{i-1}, Y_{i+1})$$ 参数化形式 根据之前对无向图模型的分解，对于线性链条件随机场，很容易验证每两个相邻的状态节点 \\(y_{i-1},y_i\\) 构成一个最大团。 于是线性链条件随机场的参数化形式可以分解为每个团上的特征函数和X对每个位置i上的特征函数： $$P(y|x) = \\frac{1}{Z(x)}exp(\\sum_{i,k}\\lambda_k t_k (y_{i-1}, y_i, x, i) + \\sum_{i, l}\\mu_l s_l (y_i, x, i)$$ 其中 \\(t_k\\) 是定义在边上的特征函数，成为 转移特征 ，依赖于当前和前一个位置(构成一个最大团)， \\(\\lambda_k\\) 是特征 \\(t_k\\) 的权重。 \\(s_l\\) 是定义在节点上的特征函数，称为 状态特征 ，依赖于当前位置， \\(\\mu_l\\) 为特征 \\(s_l\\) 的权重。 \\(t_k\\) 和 \\(s_l\\) 都依赖于位置，是局部特征函数，通常，它们的取值为1或0，当满足特征条件时值为1，反之为0. 条件随机场完全由特征函数 \\(t_k\\) 和 \\(s_l\\) 及其对应的权重 \\(\\lambda_k\\) 和 \\(\\mu_l\\) 确定。 简化形式 由参数化形式可是对于每个特征函数，它都会计算在所有位置上的值，于是可以对每个局部特征，在所有位置上求和得到一个全局特征函数。 汇总K1个转移特征和K2个状态特征： \\(k = 1, 2, ..., K_1\\) 时， \\(f_k (y_{i-1}, y_i, x, i) = t_k (y_{i-1}, y_i, x, i)\\) \\(k = K_1 +l, l = 1, 2, ... , K_2\\) 时， \\(f_k (y_{i - 1}, y_i, x, i) = s_l (y_i, x, i)\\) 对每个特征函数在所有位置求和： $$f_k (y, x) = \\sum_{i=1}&#94;n f_k(y_{i-1}, y_i, x, i), k = 1, 2, ..., K$$ 用 \\(w_k = (\\lambda_1, \\lambda_2, .., \\lambda_{K_1}, \\mu_{K_1 + 1}, .., \\mu_{K_1 + K_2})\\) 表示每个特征的权重。 于是条件随机场可以表示为： $$P(y|x) = \\frac{1}{Z(x)}exp\\sum_{k=1}&#94;K w_k f_k(y, x)$$ 如果将权重和特征函数看成向量形式， \\(w = (w_1, w_2, ..., w_K)&#94;T\\) 和 \\(F(y, x) = (f_1(y,x), f_2(y,x),...,f_K(y,x)\\) ，则可以将上式化简为： $$P_w(y|x) = \\frac{exp(w\\cdot F(y,x))}{Z_w(x)}$$ 矩阵形式 上面的简化形式是对于每个特征函数在所有位置上求和，同样的我们也可以考虑在每个位置上对所有特征函数的值求和。 $$M_i(y_{i-1}, y_i|x) = exp(W_i (y_{i-1}, y_i | x)) = exp(\\sum_{k=1}&#94;K w_k f_k(y_{i-1}, y_i, x, i)$$ 假设每个位置上的y有m个取值，则 \\(M_i(y_{i-1}, y_i)\\) 就是一个m*m阶的矩阵. 对应上面的表达式可以发现(规定 \\(y_0=start, y_{n+1} = stop\\) ) $$P(y|x) = exp(\\sum&#94;K_{k=1}\\sum&#94;{n+1}_{i=1}w_kf_k(y_{i-1},y_i,x,i) =\\prod_{i=1}&#94;{n+1}exp(\\sum_{k=1}&#94;Kw_kf_k(y_{i-1},y_i,x,i)=\\prod_{i=1}&#94;{n+1}M_i(y_{i-1},y_i|x)$$ 对于一个给定的序列，依此选取在每个矩阵中对应的元素就得到该路径的非规范概率。规范化因子则是这些矩阵的矩阵和，也对应着所有路径的非规范概率之和。 总结 ： 建立一个CRF，只需要定义一系列的特征函数，这些特征函数的值依赖于整个句子(x)，当前位置(i)和相邻的标签( \\(y_{i-1}\\) , \\(y_{i}\\) )，给出这些特征函数对应的权重，学习到这些权重值就得到了CRF的模型。 与逻辑回归和HMM的关系 逻辑回归 可以看出CRF和逻辑回归的概率表达式非常相似，因为它们都是属于log-linear模型，不同的是逻辑回归是属于分类也就是说y是一个值，而CRF的y是一个序列，CRF是一个序列版的逻辑回归。 那么如何将复杂的CRF转换为逻辑回归呢？ 考虑每个位置的特征函数 \\(f_i(x, i, y_{i-1}, y_{i})\\) 为 \\(x_i\\) ，然后其权重为 \\(w_i\\) ，这样就简化成了逻辑回归。 HMM CRF是根据定义的特征函数去求 \\(P(y|x)\\) 的得分，而HMM是用生成的方法先根据数据求 \\(P(y, x) = p(y_0)\\prod_i p(y_i|y_{i-1})p(x_i | y_i)\\) 。求对数可得： $$logp(y,x) = logp(y_0) + \\sum_i logp(y_i|y_{i-1}) + \\sum_i logp(x_i|y_i)$$ 这同样也是一个log-linear模型，将CRF中特征函数的权重等价于这些对数值就可以得到一个HMM模型： 对于HMM的转移概率 \\(p(y_i=b|y_{i-1}=a)\\) ， 定义CRF的转移特征为 \\(f(x, i, y_i, y_{i-1})=1\\) ，如果 \\(y_{i-1} = a, y_i = b\\) ，其权重为 \\(logp(y_i=b|y_{i-1}=a)\\) 对于HMM的发射概率 \\(p(x_i=b|y_i=a)\\) ，定义CRF的发射特征为 \\(f(x, i, y_i, y_{i-1}) = 1\\) 如果 \\(x_i=b, y_i=a\\) ，其权重为 \\(logp(x_i=b|y_i=a)\\) 这样就将CRF模型转换成了一个HMM模型。除此之外，CRF比HMM的更加强大： HMM的 \\(x_i\\) 只与当前的状态 \\(y_i\\) 有关，而CRF的整个序列y是和整个输入x相连的 HMM的发射概率 \\(p(x_i|y_i)\\) 是一个0到1的数，一个状态对所有发射值的概率和为1，因为是个概率值，而CRF中特征函数的权重则可以是任意值。这其实是因为 HMM的归一化发生在每一个位置，而CRF的归一化发生在整体序列上，对于中间的过程并不要求严格符合概率分布的形式。 3. CRF的概率计算 概率的计算是说在给定CRF模型P(Y|X), 输入序列x和输出序列y的情况下，计算条件概率 \\(P(Y_i = y_i|x)\\) 和 \\(P(Y_{i-1} = y_{i-1}, Y_i = y_i, x)\\) 以及相应的数学期望的问题。 前向后向算法 类似在HMM模型的情况，这里同样定义一套前向后向算法。 定义前向概率 \\(\\alpha_i(y_i | x)\\) 表示在位置i的标记是 \\(y_i\\) 并且到位置i的前部分标记序列的非规范化概率，定义后向概率 \\(\\beta_i(y_i|x)\\) 表示在位置i的标记是 \\(y_i\\) 并且从位置i+1到n的后部分标记序列的非规范化概率。 理解起来的话就是说，前向概率 \\(\\alpha_i(y_i|x)\\) 表示的是 \\(\\sum_{y_0, y_1, ..., y_{i-1}} P(y_0, y_1, .., y_{i-1}, y_i | x)\\) 对于除 \\(y_i\\) 以外的部分序列的所有情况的和。而后向概率 \\(\\beta_i(y_i|x)\\) 表示的是 \\(\\sum_{y_{n+1}, y_n, ..., y_{i+1}}P(y_{n+1}, y_n, ..., y_{i+1}, y_i|x)\\) 除 \\(y_i\\) 以外的部分序列的所有情况的和。 对于后向概率 \\(\\beta_i\\) ，这里与HMM的情形有点不同，在HMM中， \\(\\beta_i = P(o_{i+1}, o_{i+2},...|s_i)\\) 也就是说i时刻的状态是作为先验概率出现的，因为HMM的模型是概率有向图，状态是单向传递的 \\(P(y_{i+1}|y_i)\\) 。而CRF中是无向图，两者根据之前矩阵形式的推导，有类似联合概率的形式，才有了以下 \\(\\beta_i\\) 的递推公式，其中的 \\(M_{i+1}(y_i, y_{i+1}|x)\\) 既可以用于正向，也可以用于反向的推导。 对于 \\(\\alpha_0(y_0|x)\\) ，定义 \\(y_0 = start\\) 时， \\(\\alpha = 1\\) else, \\(\\alpha = 0\\) 其他位置 \\(\\alpha_i(y_i | x)\\) ，有 $$\\alpha_{i+1}(y_{i+1}|x) = \\alpha_i(y_i |x) * M_{i+1}(y_i, y_{i+1}|x)$$ 简化为 $$\\alpha_{i+1}&#94;T(x) = \\alpha_i&#94;T(x)M_{i+1}(x)$$ 由于每个位置的y有m个取值，所以这里得到的是个m维列向量。 对于 \\(\\beta_{n+1}(y_{n+1}|x)\\) ,定义 \\(y_{n+1} = stop\\) 时， \\(\\beta = 1\\) else, \\(\\beta = 0\\) 其他位置 \\(\\beta_i(y_i|x)\\) ,有 $$\\beta_i(y_i|x)=M_{i+1}(y_i, y_{i+1}|x)\\beta_{i+1}(y_{i+1}|x)$$ 简写为： $$\\beta_i(x) = M_{i+1}(x) * \\beta_{i+1}(x)$$ 规范化因子可以得出就是从start到stop的路径的非规范化概率和，相当于： $$Z(x) = \\alpha_n&#94;T(x) \\cdot \\vec{1} = \\vec{1}&#94;T \\cdot \\beta_1(x)$$ 稍微说一下个人理解，前向概率最终走到末尾节点 \\(\\alpha_n(x)\\) 的每一个分量m，对应了一个值 \\(\\alpha_n(y_n = m|x)\\) ，对各分量求和，得到整个序列的概率和。后向概率最终走到开始节点 \\(\\beta_1(x)\\) 的每一个分量m，对应了一个值 \\(y_1 = m\\) 时，从 \\(y_2\\) 到stop的这些路径的概率和，对各分量求和，同样得到整个序列的概率和。 概率计算 主要是两个概率 \\(P(Y_i = y_i|x)\\) 和 \\(P(Y_{i-1}=y_{i-1}, Y_i = y_i|x)\\) $$P(Y_i = y_i|x) = \\frac{\\alpha_i&#94;T(y_i|x)\\beta_i(y_i|x)}{Z(x)}$$ $$P(y_{i-1}, y_i |x) = \\frac{\\alpha_{i-1}&#94;T(y_{i-1}|x)M_i(y_{i-1},y_i|x)\\beta_i(y_i|x)}{Z(x)}$$ 期望计算 有了概率的定义，很自然就可以给出特征函数对应的期望。 特征函数 \\(f_k\\) 关于条件分布 \\(P(Y|X)\\) 的数学期望是： $$E_{P(Y|X)}[f_k] = \\sum_yP(y|x)f_k(y,x) = \\sum_{i=1}&#94;{n+1}\\sum_{y_{i-1}y_i}f_k(y_{i-1},y_i,x,i)*P(y_{i-1},y_i|x)$$ 假设经验分布为 \\(\\tilde{P}(X)\\) ,特征函数关于联合分布 \\(P(Y,X)\\) 的期望为： $$\\begin{aligned}E_{P(Y, X)}[f_k] &= \\sum_{x,y}P(x,y)\\sum_{i=1}&#94;{n+1}f_k(y_{i-1},y_i,x,i) \\\\\\\\&= \\sum_x\\tilde{P}(x)\\sum_yP(y|x)\\sum_{i=1}&#94;{n+1}f_k(y_{i-1},y_i,x,i)\\end{aligned}$$ 后面部分就是条件概率期望的部分。 注意到线性链CRF的特征函数是定义在 \\(y_{i-1}y_i\\) 的边上的，因此概率也拆开为对应边存在的概率 4. CRF的预测算法 CRF的预测算法就是在给定CRF模型P(Y|X)和观测序列x的情况下给出概率最大的输出序列，通常情况也就是对于观测序列进行标注。 用公式表示就是： $$y&#94;* = argmax_y P(Y|X) = argmax_y \\frac{exp(w\\cdot F(y, x))}{Z} = argmax_y (w\\cdot F(y, x))$$ 因为只是求概率最大的路径而不是求真实的概率值，所以这里只要求非规范化概率即可，提高了效率。 将其分解到每个位置就将问题转换为 $$max\\sum_i&#94;nw\\cdot F_i(y_{i-1}, y_i,x)$$ 其中 \\(w=(w_1, w_2, ..., w_k)\\) ，对应k个特征函数的权重， \\(F_i(y_{i-1}, y_i, x) = (f_1(y_{i-1}, y_i, x), f_2(y_{i-1}, y_i, x),...,f_k(y_{i-1}, y_i, x))\\) 对应每个特征函数在位置i上的值，两向量的乘积就表示从 \\(y_{i-1}\\) 到 \\(y_i\\) 上的\"概率\"。 注意上面对于整个路径的概率并没有求乘积，而是求和，这是因为 \\(w\\cdot F\\) 是从 \\(exp(w\\cdot F)\\) 中提取出来的，求和就等价于整体求乘积。 预测算法 对于一条路径，求出所有位置所有状态的组合，最后选择概率最大的，这种方法肯定是不现实的，效率非常低（ \\(O(n&#94;T)\\) ）。 对于这种求最优序列的问题，在每个位置有n个状态，总体概率可以拆解为相邻位置的状态转移概率，求整体最优的序列都可以使用维特比算法，也就是一种动态规划求最优解的方法。 简单描述： 初始位置t=0，计算每个状态 \\(y_0\\) 的概率，就得到n个概率值（假设有n个可能的状态） 在位置t=1，针对每个状态 \\(y_1\\) ，求出使得 \\(y_0, y_1\\) 序列概率最大的 \\(y_0\\) ,这样又得到n个概率（每个 \\(y_1\\) 对应一个 \\(y_0\\) ），记录下此时的n个 \\(y_0\\) 依次递推，每个时刻记录n个概率值，当到达最终点的时候，选出概率最大的状态进行回溯就得到最优路径 通过上面的方法，每个位置都只要计算 \\(n&#94;2\\) 次，时间复杂度为 \\(O(kn&#94;2)\\) 与之前 \\(O(n&#94;k)\\) 相比大为减少。 5. CRF的学习算法 CRF模型的学习就是学习每个特征函数的权重，通常情况下采用最大似然估计的方法进行学习。对于单样本的情况，给定x，y给出CRF的模型的条件概率： $$p(y|x) = \\frac{exp(\\sum_{k=1}&#94;K\\sum_{i=1}&#94;nw_kf_k(y_{i-1}, y_i, x, i)}{\\sum_{y'}exp(\\sum_{k=1}&#94;K\\sum_{i=1}&#94;nw_kf_k(y'_{i-1}, y'_i, x, i)}$$ 先进行log简化一下为： $$logp(y|x) = \\sum_{k=1}&#94;K\\sum_{i=1}&#94;nw_kf_k(y_{i-1}, y_i, x, i) - log\\sum_{y'}exp(\\sum_{k=1}&#94;K\\sum_{i=1}&#94;nw_kf_k(y'_{i-1}, y'_i, x, i)$$ 采用梯度下降法，对第j个特征函数的权重 \\(w_j\\) 求导： $$\\begin{aligned}\\frac{\\partial logp}{\\partial w_j} &= \\sum_{i=1}&#94;nw_jf_j(y_{i-1}, y_i, x, i) - \\frac{\\sum_{y'}exp(\\sum_{k=1}&#94;K\\sum_{i=1}&#94;nw_kf_k(y'_{i-1}, y'_i, x, i))\\sum_{i=1}&#94;nw_jf_j(y'_{i-1}, y'_i, x, i)}{\\sum_{y'}exp(\\sum_{k=1}&#94;K\\sum_{i=1}&#94;nw_kf_k(y'_{i-1}, y'_i, x, i))} \\\\\\\\ &=\\sum_{i=1}&#94;nf_j(y_{i-1}, y_i, x, i) - \\sum_{y'} p(y'|x) \\sum_{i=1}&#94;nf_j(y'_{i-1}, y'_i, x, i)\\end{aligned}$$ 有了梯度函数按照梯度负方向重复进行更新： $$w_j := w_j - \\alpha \\frac{\\partial logp}{\\partial w_j}$$ 就可以得到最后收敛的参数了。 参考资料 [1] 统计学习方法 - 李航 [2] Introduction to Conditional Random Fields - Edwin Chen if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"tiao-jian-sui-ji-chang-crf.html"},{"title":"指数分布族和广义线性回归","text":"指数分布族 1. 定义 指数分布族不是专指一种分布，而是一系列符合特征的分布的统称。常用的诸如正态分布，伯努利分布，指数分布，泊松分布，gamma分布都属于指数分布族。 $$p(y;\\theta) = b(y)exp(\\eta(\\theta)T(y) - A(\\theta))$$ 其中： b(y) - underlying measure T(y) - sufficient statistic A( \\(\\theta\\) ) - log normalizer 通常情况下T(y) = y, A, b, T, \\(\\eta\\) 给定的不同，就能得到不同的y的分布 其中的变量y和参数 \\(\\theta\\) 只在 \\(T(y)\\eta(\\theta)\\) 中有联系，T(y)和 \\(\\eta(\\theta)\\) 都是向量形式 2. 伯努利分布 伯努利分布的概率密度函数为： $$p(y;\\theta) = \\theta&#94;y(1 - \\theta)&#94;{1-y} = exp(ylog\\theta + (1-y)log(1-\\theta) = exp(log\\frac{\\theta}{1 - \\theta}y + log(1-\\theta))$$ 对应指数分布族的概率密度函数可以发现： \\(b(y) = 1\\) \\(\\eta(\\theta) = log\\frac{\\theta}{1 - \\theta}\\) \\(T(y) = y\\) \\(A(\\theta) = -log(1 - \\theta) = log(1 + e&#94;{\\eta(\\theta)})\\) 3. 高斯分布 对于均值为 \\(\\mu\\) ，方差为 \\(\\sigma\\) 的高斯分布的概率密度函数为： $$p(y;\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e&#94;{-\\frac{(y-\\mu)&#94;2}{2\\sigma&#94;2}} = \\frac{1}{\\sqrt{2\\pi}}e&#94;{\\eta(\\mu, \\sigma)T(y) - log\\sigma - \\frac{\\mu&#94;2}{2\\sigma&#94;2}}$$ 对应指数分布族的概率密度函数可以发现: \\(b(y) = \\frac{1}{\\sqrt{2\\pi}}\\) \\(\\eta(\\sigma) = [\\frac{\\mu}{\\sigma&#94;2}, -\\frac{1}{2\\sigma&#94;2}]\\) \\(T(y) = [y, y&#94;2]\\) \\(A(\\sigma) = \\frac{\\mu&#94;2}{2\\sigma&#94;2} + log\\sigma\\) 4. 其他指数分布 还有许多其他分布属于指数分布族，如： 多项式分布（multinomial），用来对多元分类问题进行建模； 泊松分布（Poisson），用来对计数过程进行建模，如网站的访客数量、商店的顾客数量等； 伽马分布（gamma）和指数分布（exponential），用来对时间间隔进行建模，如等车时间等； β分布（beta）和Dirichlet分布（Dirichlet），用于概率分布； Wishart分布（Wishart），用于协方差矩阵分布。 广义线性模型(GLM) 之前一直知道线性回归，逻辑回归都属于glm，其中线性回归假设服从高斯分布，逻辑回归假设服从伯努利分布，但是为什么要这样并不是非常清楚。 1. 三个假设 在给定自变量x和参数 \\(\\theta\\) 的情况下，因变量y服从指数分布族 给定x，最终目的是求出T(y)的期望E[T(y)|x] 自然参数 \\(\\eta\\) 可以表示为自变量x的线性关系，即 \\(\\eta = \\theta&#94;T x\\) 广义线性模型通过拟合y的条件均值/期望(在x和参数 \\(\\theta\\) 给定的情况下)，并假设y符合指数分布族中的某种分布，从而扩展了标准线性模型 2. 高斯分布 对于高斯分布，y的均值为参数 \\(\\mu\\) 根据上面的推导， \\(y = \\mu = \\eta = \\theta&#94;T x\\) (假设 \\(\\sigma = 1\\) ) 这就和线性回归对于y作高斯分布的假设相呼应，这里的link function是y=x为identity function 3. 伯努利分布 对于伯努利分布，y的均值为 \\(\\phi\\) ，就是指数分布族下的唯一参数 根据上面的推导， \\(\\eta = log\\frac{\\phi}{1 - \\phi} = \\theta&#94;T x\\) 推导出 \\(y = \\phi = \\frac{1}{1 + e&#94;{-\\eta}} = \\frac{1}{1 + e&#94;{-\\theta&#94;T x}}\\) 这也就是逻辑回归的表达式，对应与逻辑回归下y作伯努利分布的假设，此时的link function为 \\(y = log \\frac{x}{1 - x}\\) ，就是大名鼎鼎的logit函数了。 4. GLM建模过程 总结一下GLM的建模过程。 根据问题在指数分布族中选择一种分布作为对y的假设 计算该分布下的 \\(\\eta\\) ，实际上 \\(\\eta = \\eta(w&#94;T)\\) ，其中\\ \\(w&#94;T\\) 为该分布的真实参数，而 \\(\\eta\\) 只是以 \\(w&#94;T\\) 为参数的一个link function 计算该分布的期望，将其用 \\(\\eta\\) 表示，例如上面伯努利分布时的 \\(y=\\phi = \\frac{1}{1+e&#94;{-\\eta}}\\) 根据GLM的假设替换 \\(\\eta = \\theta&#94;T x\\) 即得到GLM模型 将这些知识都串联起来，就能更好的理解不同回归模型下的前提假设及其link function的选择了。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"机器学习","url":"zhi-shu-fen-bu-zu-he-yan-yi-xian-xing-hui-gui.html"},{"title":"信息论基本概念","text":"最近在看《统计自然语言处理》，觉得第二章预备知识里的关于信息论的一些基本概念总结得很不错。虽然对于熵这个词，我接触过很多次，在机器学习里的很多地方也都有涉及到，比如说最大熵模型，决策树训练时的互信息等等。但是有的时候我还是会经常搞混淆，这里简单介绍一下常用的概念。 一. 熵 对于离散变量 \\(X\\) , 假设其取值空间为 \\(R\\) ，其概率分布为 \\(p(x) = P(X = x), x \\in R\\) ，那么定义随机变量 \\(X\\) 的熵为： $$H(X) = - \\sum_{x \\in R} p(x)log_x (p(x))$$ 约定 \\(0log(0) = 0\\) 。由于这里使用了2为底，所以该公式定义的熵的单位为二进制单位(比特)，实际情况也有使用其它底数的版本的熵。 熵又被成为自信息(self-information)，可以将其描述为一个随机变量不稳定的程度。通过简单的数学计算可以证明当随机变量 \\(X\\) 在其取值空间上对所有值等概率的情况下，熵达到最大值，也就是说随机变量随机性越强，它的熵越大。如果在某一个值上取值概率为1，也就是说这个随机变量其实并不随机，是一个定值，这个时候的熵达到最小值0，它毫无随机性。 熵还可以表示信源 \\(X\\) 每发出一个符号所提供的平均信息量。熵越大，越难猜测变量正确的值，因此给予的信息就越多。 二. 联合熵和条件熵 有了单变量的情况，很自然就想到多变量下联合概率和条件概率的情况。 对于一堆随机变量 \\(X, Y\\) ，其联合概率为 \\(p(x, y)\\) ，则其联合熵为： $$H(X, Y) = - \\sum_{x\\in X} \\sum_{y \\in Y} log_2(p(x, y))$$ 联合熵实际熵就是描述一对随机变量平均所需要的信息量。 条件熵就是给定条件概率 \\(p(Y|X)\\) 的情况下： $$\\begin{aligned} H(Y|X) &= \\sum_{x\\in X} p(x)H(Y|X = x) = \\sum_{x \\in X}\\sum_{y\\in Y}p(x)p(y|x)log(p(y|x) \\\\\\\\ &= \\sum_{x\\in X}\\sum_{y \\in Y}p(x)\\frac{p(x,y)}{p(x)}log(\\frac{p(x,y)}{p(x)}) \\\\\\\\ &= \\sum_{x\\in X}\\sum_{y \\in Y}p(x,y)log(p(x,y) - p(x,y)logp(x) \\\\\\\\ &= \\sum_{x\\in X}\\sum_{y \\in Y}p(x, y)log(p(x,y) - \\sum_{x\\in X}p(x)log(p(x)) \\\\\\\\ &= H(X, Y) - H(X)\\end{aligned}$$ 这个式子也被称为熵的连锁规则，推广到一般情况有： $$H(X_1, X_2, ..., X_n) = H(X_1) + H(X_2|X_1) + H(X_3|X_2, X_2) + ... + H(X_n|X_{n-1}, X_{n-2},...,X_1)$$ 条件熵可以看作是在受变量 \\(X\\) 影响的情况下，变量 \\(Y\\) 的不稳定程度。 对于来自于同一个分布 \\(X\\) 的一个随机变量序列 \\((X_1, X_2, ..., X_n)\\) ，用 \\(X_{1n}\\) 表示。当我们求这个序列的熵的时候，我们可以将其表示为 \\(n\\) 个同样的随机分布 \\(X\\) 的联合熵，为 \\(-\\sum_{x_{1n}} p(x_{1n})log(p(x_{1n}))\\) 。 于是，对于一条长度为n的信息，每一个字符或字的熵为： $$H_{rate} = \\frac{1}{n}H(X_{1n}) = -\\frac{1}{n}\\sum_{x_{1n}} p(x_{1n})log(p(x_{1n}))$$ 这个数值被称为熵率。 对于语言模型来说，如果假定一种语言是由一系列符号组成的随机过程 \\(L=(X_i)\\) ，例如，某报纸的一批预料，那么，可以定义这种语言L的熵率作为其随机过程的熵率： $$H_{rate} = lim_{n \\rightarrow \\infty}\\frac{1}{n}H(X_{1n})$$ 三. 互信息 根据上面的链式法则得到： $$H(X, Y) = H(X) + H(Y|X) = H(Y) + H(X|Y)$$ 于是有: $$H(X) - H(X|Y) = H(Y) - H(Y|X)$$ 这个差值被称为变量 \\(X\\) 和 \\(Y\\) 之间的互信息，计作 \\(I(X; Y)\\) 。它反映了在知道了 \\(Y\\) 的值以后， \\(X\\) 的不确定性的减少量，同时也是在知道了 \\(X\\) 的值以后， \\(Y\\) 的不确定性的减少量。可以理解为 \\(Y\\) 的值透露了多少关于 \\(X\\) 的信息量。 将其展开: $$\\begin{aligned}I(X;Y) &= H(X)-H(X|Y) = H(X) + H(Y) - H(X, Y) \\\\\\\\ &= -\\sum_x p(x)log(p(x)) - \\sum_y p(y)log(p(y)) + \\sum_{x, y} p(x, y)log(p(x, y)) \\\\\\\\ &= \\sum_{x, y}p(x,y)log\\frac{p(x, y)}{p(x)p(y)}\\end{aligned}$$ 从这个式子可以看出 \\(I(X;X) = H(X) - H(X|X) = H(X)\\) ，这也就是把熵称为自信息的原因。另一方面可以看出，如果 \\(I(X;Y)>>0\\) ，则表明 \\(X\\) 和 \\(Y\\) 是高度相关的。如果 \\(I(X;Y) = 0\\) ，即 \\(p(x,y)=p(x)p(y)\\) 则说明两者完全独立。如果 \\(I(X;Y)<<0\\) ，则表明 \\(Y\\) 的出现不但未使 \\(X\\) 的不确定性降低，反而加大了其不确定性，这通常是不利的。 同样可以推导条件互信息。 条件互信息： $$\\begin{aligned}I(X;Y|Z) &= I((X;Y | Z)) = H(X|Z) - H(X|Y,Z) \\\\\\\\ &= H(X) - I(X;Z) - (H(X) - I(X;Y,Z)) \\\\\\\\ &= I(X;Y,Z) - I(X;Z)\\end{aligned}$$ 四. 相对熵 相对熵又被称为KL距离，是衡量相同事件空间里两个概率分布相对差距的测度。两个概率分布 \\(p(x)\\) 和 \\(q(x)\\) 的相对熵定义为： $$D(p||q) = \\sum_{x\\in X}p(x)log\\frac{p(x)}{q(x)} = E_p(log\\frac{p(x)}{q(x)})$$ 显然，当两个随机分布完全相同，即 \\(p=q\\) 时，相对熵为0，当其差别增加时，其相对熵的期望值也增大。 之前证明了 $$I(X;Y) = \\sum_{x, y}p(x,y)log\\frac{p(x, y)}{p(x)p(y)} = D(p(x,y)||p(x)p(y)$$ 于是知道互信息就是衡量一个联合分布与独立性差距多大的测度。 五. 交叉熵 根据前面的定义，知道熵就是一个不确定性的测度。对于某件事情，我们知道的越多，熵就越小，因而我们对于试验的结果就越不感到意外。交叉熵的概念就是用来衡量估计模型与真是概率分布之间差异情况的。 如果一个随机变量 \\(X\\sim p(x)\\) ， \\(q\\) 是我们计算得到的模型， \\(q(x)\\) 是模型 \\(q\\) 对于真实分布 \\(p(x)\\) 的近似表示。那么随机变量 \\(X\\) 和模型 \\(q\\) 之间的交叉熵定义为： $$\\begin{aligned}H(X, q) = H(X) + D(p || q) &= -\\sum_{x\\in X} p(x)log(p(x)) + \\sum_{x\\in X} p(x)log\\frac{p(x)}{q(x)} \\\\\\\\ &= -\\sum_{x\\in X}p(x)log(q(x)) = E_p(log\\frac{1}{q(x)})\\end{aligned}$$ 这里联想到之前在介绍神经元交叉熵损失的时候给出了这样一个定义 \\(yln(a) + (1-y)ln(a)\\) ，可以知道这里的 \\(y\\) 并不是对应说真实的标签，而是对于该神经元的两种状态0或1，当其真实值为1时，即 \\(p(x = 1) = 1\\) ,损失为 \\(log(q(x=1)\\) ，当其真实值为0时，即 \\(p(x=0) = 1\\) ,损失就是 \\(log(1-q(x=1) = log(q(x=0))\\) ，和我们这里交叉熵的定义完全符合。 注意到这里交叉熵写作 \\(H(X, q)\\) ，这似乎就是联合熵的形式，这样表示不会引起误会吗？事实上，交叉熵可以看作是一种特殊场景下的联合熵，它是衡量一个变量 \\(X\\) ，和我们对其的近似表示 \\(q(x)\\) 的联合熵。如何这个近似非常完美，即 \\(q(x)\\) 就是 \\(X\\) 的真实分布 \\(p(x)\\) ，那么 \\(D(p||q) = 0, H(X, q) = H(X, X)\\) ，就是自身的联合熵了。 接着我们定义一个语言 \\(L = (X) \\sim p(x)\\) 与我们构建的语言模型 \\(q\\) 的交叉熵为： $$H(L, q) = -lim_{n\\rightarrow \\infty}\\frac{1}{n} \\sum_{x&#94;n_1} p(x&#94;n_1)log(q(x&#94;n_1))$$ 其中， \\(x&#94;n_1 = x_1, x_2, .. ,x_n\\) 为语言 \\(L\\) 的词序列样本，这里的词包括样本中出现的任意词汇、数字、标点等。我们假设这种语言是\"理想\"的，于是有n趋于无穷大时，有全部\"词汇\"的概率和为1，根据信息论的定理，假定语言L是稳态遍历的随机过程，就可以得到： $$H(L, q) = -lim_{n\\rightarrow \\infty}\\frac{1}{n} log(q(x&#94;n_1))$$ 就是说可以用样本的熵表示整个语言的熵。 在实际情况下，当我们选择的样本量n足够大的时候，可以将上式子近似表示为 \\(-\\frac{1}{N}log(q(x&#94;N_1)\\) ，交叉熵越小，表示我们的模型越接近真实的语言模型，效果越好。 六. 困惑度 在设计语言模型的时候，我们通常并不使用交叉熵而是使用困惑度(perplexity)来表示。给定语言L的样本 \\(l&#94;n_1 = l_1...l_n\\) ,L的困惑度PP_q为： $$pp_q = 2&#94;{H(L,q)} \\approx 2&#94;{-\\frac{1}{n}log(q(l&#94;n_1)} = [q(l&#94;n_1)]&#94;{-\\frac{1}{n}}$$ 于是语言模型设计的任务就是寻找困惑度最小的模型，使其最接近真实语言的情况。 从perplexity的计算式可以看出来，它是对于样本句子出现的概率，在句子长度上Normalize一下的结果。它越小，说明出现概率越大，所得模型就越好。 七. 模拟信道模型 在学通信原理的时候学习过信道的概念，一个信号经过一个信道，会由于压缩编码，噪声引入，然后在解码的时候就会多少有一点失真。 在自然语言处理中，很多问题也都可以归结为这样的模型。给定输出 \\(O\\) (可能含有误传信息)的情况下，如何从所有可能的输入 \\(I\\) 中选出最可能的那个： $$\\hat{I} = argmax_I p(I|O) = argmax_I \\frac{P(I)p(O|I)}{p(O)} = argmax_I p(I)p(O|I)$$ 其中 \\(p(I)\\) 成为语言模型，是指在输入语言中\"词\"序列的概率分布；另一个 \\(p(O|I)\\) 成为信道概率。 对应到实际的NLP问题，比如说机器翻译在进行汉译英的时候，汉语句子看作是信道输出O，求出最可能的信道输入英语句子I。 噪声信道模型在NLP中有非常多的用途，除了机器翻译以外，还用于词性标注、语音识别、文字识别等很多问题的研究。 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"NLP","url":"xin-xi-lun-ji-ben-gai-nian.html"}]}